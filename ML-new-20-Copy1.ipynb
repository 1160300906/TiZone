{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cmeclose</th>\n",
       "      <th>cmcclose</th>\n",
       "      <th>google</th>\n",
       "      <th>ravenpack</th>\n",
       "      <th>XAUprice</th>\n",
       "      <th>cmcvolume</th>\n",
       "      <th>market</th>\n",
       "      <th>AveBlockSize</th>\n",
       "      <th>AveTimeMaBlock</th>\n",
       "      <th>AveTran</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA</th>\n",
       "      <th>RSI</th>\n",
       "      <th>TRIX</th>\n",
       "      <th>ROC</th>\n",
       "      <th>macd</th>\n",
       "      <th>macdsignal</th>\n",
       "      <th>macdhist</th>\n",
       "      <th>ADX</th>\n",
       "      <th>ATR</th>\n",
       "      <th>CCI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>8525</td>\n",
       "      <td>7916.88</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.26495</td>\n",
       "      <td>1314.00</td>\n",
       "      <td>4426149888</td>\n",
       "      <td>1.400000e+11</td>\n",
       "      <td>0.515428</td>\n",
       "      <td>9.757606</td>\n",
       "      <td>1036.885906</td>\n",
       "      <td>...</td>\n",
       "      <td>10075.114333</td>\n",
       "      <td>34.059231</td>\n",
       "      <td>-0.406550</td>\n",
       "      <td>-20.557680</td>\n",
       "      <td>-562.998249</td>\n",
       "      <td>-323.773162</td>\n",
       "      <td>-239.225087</td>\n",
       "      <td>27.230875</td>\n",
       "      <td>5249.784653</td>\n",
       "      <td>23.037639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>8525</td>\n",
       "      <td>8223.68</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.25410</td>\n",
       "      <td>1314.00</td>\n",
       "      <td>6639190016</td>\n",
       "      <td>1.320000e+11</td>\n",
       "      <td>0.695280</td>\n",
       "      <td>9.535099</td>\n",
       "      <td>1088.748344</td>\n",
       "      <td>...</td>\n",
       "      <td>10008.107000</td>\n",
       "      <td>37.659176</td>\n",
       "      <td>-0.415854</td>\n",
       "      <td>-12.467576</td>\n",
       "      <td>-584.029909</td>\n",
       "      <td>-375.824512</td>\n",
       "      <td>-208.205398</td>\n",
       "      <td>28.866723</td>\n",
       "      <td>5044.276463</td>\n",
       "      <td>67.378755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>8425</td>\n",
       "      <td>8630.65</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.22823</td>\n",
       "      <td>1316.94</td>\n",
       "      <td>6729110016</td>\n",
       "      <td>1.410000e+11</td>\n",
       "      <td>0.678045</td>\n",
       "      <td>9.210215</td>\n",
       "      <td>1235.664516</td>\n",
       "      <td>...</td>\n",
       "      <td>9925.372000</td>\n",
       "      <td>42.169334</td>\n",
       "      <td>-0.424889</td>\n",
       "      <td>-7.570508</td>\n",
       "      <td>-561.387251</td>\n",
       "      <td>-412.937059</td>\n",
       "      <td>-148.450191</td>\n",
       "      <td>29.957411</td>\n",
       "      <td>4880.468144</td>\n",
       "      <td>118.341588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>8920</td>\n",
       "      <td>8913.47</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.17697</td>\n",
       "      <td>1311.21</td>\n",
       "      <td>6361789952</td>\n",
       "      <td>1.440000e+11</td>\n",
       "      <td>0.793883</td>\n",
       "      <td>11.406955</td>\n",
       "      <td>1536.755906</td>\n",
       "      <td>...</td>\n",
       "      <td>9870.761000</td>\n",
       "      <td>45.139699</td>\n",
       "      <td>-0.432832</td>\n",
       "      <td>0.535416</td>\n",
       "      <td>-514.688561</td>\n",
       "      <td>-433.287360</td>\n",
       "      <td>-81.401201</td>\n",
       "      <td>29.302440</td>\n",
       "      <td>4780.378277</td>\n",
       "      <td>82.767388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>8895</td>\n",
       "      <td>8929.28</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.15176</td>\n",
       "      <td>1332.18</td>\n",
       "      <td>6043129856</td>\n",
       "      <td>1.510000e+11</td>\n",
       "      <td>0.670269</td>\n",
       "      <td>9.455373</td>\n",
       "      <td>1281.881579</td>\n",
       "      <td>...</td>\n",
       "      <td>9794.227000</td>\n",
       "      <td>45.308811</td>\n",
       "      <td>-0.439656</td>\n",
       "      <td>-6.779153</td>\n",
       "      <td>-470.974675</td>\n",
       "      <td>-440.824823</td>\n",
       "      <td>-30.149852</td>\n",
       "      <td>29.095382</td>\n",
       "      <td>4680.523400</td>\n",
       "      <td>121.752525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cmeclose  cmcclose  google  ravenpack  XAUprice   cmcvolume        market  \\\n",
       "88      8525   7916.88      11   -0.26495   1314.00  4426149888  1.400000e+11   \n",
       "89      8525   8223.68      13   -0.25410   1314.00  6639190016  1.320000e+11   \n",
       "90      8425   8630.65      12   -0.22823   1316.94  6729110016  1.410000e+11   \n",
       "91      8920   8913.47      12   -0.17697   1311.21  6361789952  1.440000e+11   \n",
       "92      8895   8929.28      11   -0.15176   1332.18  6043129856  1.510000e+11   \n",
       "\n",
       "    AveBlockSize  AveTimeMaBlock      AveTran  ...           SMA        RSI  \\\n",
       "88      0.515428        9.757606  1036.885906  ...  10075.114333  34.059231   \n",
       "89      0.695280        9.535099  1088.748344  ...  10008.107000  37.659176   \n",
       "90      0.678045        9.210215  1235.664516  ...   9925.372000  42.169334   \n",
       "91      0.793883       11.406955  1536.755906  ...   9870.761000  45.139699   \n",
       "92      0.670269        9.455373  1281.881579  ...   9794.227000  45.308811   \n",
       "\n",
       "        TRIX        ROC        macd  macdsignal    macdhist        ADX  \\\n",
       "88 -0.406550 -20.557680 -562.998249 -323.773162 -239.225087  27.230875   \n",
       "89 -0.415854 -12.467576 -584.029909 -375.824512 -208.205398  28.866723   \n",
       "90 -0.424889  -7.570508 -561.387251 -412.937059 -148.450191  29.957411   \n",
       "91 -0.432832   0.535416 -514.688561 -433.287360  -81.401201  29.302440   \n",
       "92 -0.439656  -6.779153 -470.974675 -440.824823  -30.149852  29.095382   \n",
       "\n",
       "            ATR         CCI  \n",
       "88  5249.784653   23.037639  \n",
       "89  5044.276463   67.378755  \n",
       "90  4880.468144  118.341588  \n",
       "91  4780.378277   82.767388  \n",
       "92  4680.523400  121.752525  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "dataframe1 = read_csv('newDailyData.csv', engine='python')\n",
    "dataframe = dataframe1.iloc[88:,2:]\n",
    "dataset = dataframe.values\n",
    "# 将整型变为float\n",
    "dataset = dataset.astype('float64')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(746, 40)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = dataframe1.iloc[:,1:2].values\n",
    "scaler1 = OneHotEncoder()\n",
    "labels = scaler1.fit_transform(labels1)\n",
    "\n",
    "labels=labels.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset,dataset1,dataset2,look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(0,len(dataset)-look_back,1):\n",
    "        a1 = dataset[i:(i+look_back),:]\n",
    "        a2 = dataset1[i:(i+look_back),:]\n",
    "        a = numpy.hstack((a1,a2))\n",
    "        dataX.append(a)\n",
    "        b = dataset1[(i+look_back):(i+look_back+1),1]\n",
    "        dataY.append(b)\n",
    "    return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(580, 20, 42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_back = 20\n",
    "look_lag = 1 #用前20个数据预测当前1个数据\n",
    "train_size = 600\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[:train_size,:], dataset[train_size-look_back:len(dataset),:]\n",
    "train1, test1 = labels[:train_size,:], labels[train_size-look_back:len(dataset),:]\n",
    "train2, test2 = labels1[:train_size,:], labels1[train_size-look_back:len(dataset),:]\n",
    "train1, test1 = labels[:train_size,:], labels[train_size-look_back:len(dataset),:]\n",
    "trainX, trainY = create_dataset(train,train1,train2,look_back)\n",
    "testX, testY = create_dataset(test, test1 ,test2,look_back)\n",
    "print(trainX.shape)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], look_back,42))\n",
    "testX = numpy.reshape(testX, (testX.shape[0],look_back,42))\n",
    "\n",
    "features_set = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1]*42))\n",
    "scaler1 = StandardScaler().fit(features_set) #MinMaxScaler(feature_range=(-1, 1))\n",
    "#features_set = scaler1.fit_transform(features_set)\n",
    "#pca=PCA(n_components=500).fit(features_set)\n",
    "#features_set = pca.transform(features_set)\n",
    "test_features = numpy.reshape(testX, (testX.shape[0], testX.shape[1]*42))\n",
    "#test_features = scaler1.fit_transform(test_features)\n",
    "#test_features = pca.transform(test_features)\n",
    "\n",
    "def result(testY,testPredict):\n",
    "    from sklearn.metrics import accuracy_score,classification_report\n",
    "    acc = accuracy_score(testY,testPredict)\n",
    "    report = classification_report(testY,testPredict)\n",
    "    print(\"acc:\",acc)\n",
    "    print(report)\n",
    "\n",
    "trainY = trainY.reshape(trainY.shape[0])\n",
    "testY = testY.reshape(testY.shape[0])\n",
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "model1 = LR() #C=100,max_iter=1000\n",
    "model1.fit(features_set, trainY)\n",
    "testPredict1 = model1.predict(test_features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.5616438356164384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.81      0.68        84\n",
      "         1.0       0.47      0.23      0.30        62\n",
      "\n",
      "    accuracy                           0.56       146\n",
      "   macro avg       0.53      0.52      0.49       146\n",
      "weighted avg       0.54      0.56      0.52       146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result(testY,testPredict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.4657534246575342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.31      0.40        84\n",
      "         1.0       0.42      0.68      0.52        62\n",
      "\n",
      "    accuracy                           0.47       146\n",
      "   macro avg       0.49      0.49      0.46       146\n",
      "weighted avg       0.50      0.47      0.45       146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "model2 = LinearDiscriminantAnalysis() \n",
    "model2.fit(features_set, trainY)\n",
    "testPredict2 = model2.predict(test_features)  \n",
    "result(testY,testPredict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.5684931506849316\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.67      0.64        84\n",
      "         1.0       0.49      0.44      0.46        62\n",
      "\n",
      "    accuracy                           0.57       146\n",
      "   macro avg       0.55      0.55      0.55       146\n",
      "weighted avg       0.56      0.57      0.56       146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "model3 = QuadraticDiscriminantAnalysis() \n",
    "model3.fit(features_set, trainY)\n",
    "testPredict3 = model3.predict(test_features)  \n",
    "result(testY,testPredict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: xgboost in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from xgboost) (1.18.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from xgboost) (1.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.4794520547945205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.38      0.46        84\n",
      "         1.0       0.42      0.61      0.50        62\n",
      "\n",
      "    accuracy                           0.48       146\n",
      "   macro avg       0.50      0.50      0.48       146\n",
      "weighted avg       0.51      0.48      0.48       146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "model4 = xgb.XGBClassifier()\n",
    "'''\n",
    "objective ='reg:logistic', colsample_bytree = 0.5, learning_rate = 0.003,\n",
    "                max_depth = 20, alpha = 20, n_estimators = 400\n",
    "'''\n",
    "model4.fit(features_set, trainY)\n",
    "testPredict4 = model4.predict(test_features)  \n",
    "result(testY,testPredict4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.4041095890410959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        84\n",
      "         1.0       0.41      0.95      0.58        62\n",
      "\n",
      "    accuracy                           0.40       146\n",
      "   macro avg       0.21      0.48      0.29       146\n",
      "weighted avg       0.18      0.40      0.24       146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "model5 = svm.SVC()\n",
    "model5.fit(features_set, trainY)\n",
    "testPredict5 = model5.predict(test_features)  \n",
    "result(testY,testPredict5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=400)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "regr = RandomForestClassifier(n_estimators=400,criterion=\"entropy\")#n_estimators=400,criterion=\"entropy\"\n",
    "regr.fit(features_set, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.4315068493150685\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.10      0.16        84\n",
      "         1.0       0.42      0.89      0.57        62\n",
      "\n",
      "    accuracy                           0.43       146\n",
      "   macro avg       0.48      0.49      0.37       146\n",
      "weighted avg       0.49      0.43      0.34       146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testPredict6 = regr.predict(test_features)  \n",
    "result(testY,testPredict6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting keras==2.2.4\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
      "\u001b[K     |████████████████████████████████| 312 kB 750 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 37.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /opt/conda/envs/python3/lib/python3.6/site-packages (from keras==2.2.4) (1.15.0)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 43.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/python3/lib/python3.6/site-packages (from keras==2.2.4) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python3/lib/python3.6/site-packages (from keras==2.2.4) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/envs/python3/lib/python3.6/site-packages (from keras==2.2.4) (1.5.0)\n",
      "Collecting h5py\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: keras-preprocessing, h5py, keras-applications, keras\n",
      "Successfully installed h5py-2.10.0 keras-2.2.4 keras-applications-1.0.8 keras-preprocessing-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5376850f2dc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.6/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.6/site-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Globally-importable utils.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.6/site-packages/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.6/site-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Try and load external backend.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import keras\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,Conv1D,Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "%matplotlib inline\n",
    "from keras import optimizers,initializers\n",
    "model = Sequential() \n",
    "\n",
    "model.add(LSTM(units=96, return_sequences=True, \n",
    "               input_shape=(trainX.shape[1],trainX.shape[2])))#\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(LSTM(units=48, return_sequences=True,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(units=48,return_sequences=False,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "'''\n",
    "model.add(Conv1D(kernel_size=20, filters=3,activation='relu'))\n",
    "model.add(Flatten())\n",
    "'''\n",
    "\n",
    "#model.add(Dense(units = 16,activation='relu'))\n",
    "model.add(Dense(units = 1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',#binary_crossentropy\n",
    "                  optimizer='adam',#RMSprop optimizers.Adam(lr=0.00001)\n",
    "                  metrics=['accuracy'])  #mean_squared_error metrics=['accuracy']\n",
    "history = model.fit(trainX,trainY,epochs=500, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.5144230769230769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.42      0.49       115\n",
      "         1.0       0.47      0.63      0.54        93\n",
      "\n",
      "    accuracy                           0.51       208\n",
      "   macro avg       0.53      0.53      0.51       208\n",
      "weighted avg       0.53      0.51      0.51       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testPredict = model.predict_classes(testX)\n",
    "result(testY,testPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_py3",
   "language": "python",
   "name": "conda_tensorflow_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
