{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43584, 8)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline\n",
    "\n",
    "# load the dataset\n",
    "dataframe = read_csv('intecleaned-correct.csv',usecols=[1,2,4,5,6,7,8,9])\n",
    "dataset = dataframe.values\n",
    "#将整型变为float\n",
    "dataset = dataset.astype('float32')\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# normalize the dataset\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))#功率数据归一化，之后还原预测结果要用\n",
    "Y = scaler_y.fit_transform(dataset[:,5:6])\n",
    "\n",
    "scaler_y1 = MinMaxScaler(feature_range=(0, 1))#风速数据归一化\n",
    "Y1 = scaler_y1.fit_transform(dataset[:,6:7])\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>短期预测功率</th>\n",
       "      <th>短期预测湿度</th>\n",
       "      <th>短期预测风向</th>\n",
       "      <th>短期预测温度</th>\n",
       "      <th>短期预测气压</th>\n",
       "      <th>实际功率</th>\n",
       "      <th>实际风速</th>\n",
       "      <th>短期预测风速</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.41</td>\n",
       "      <td>75</td>\n",
       "      <td>41</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1008</td>\n",
       "      <td>28.59</td>\n",
       "      <td>8.50</td>\n",
       "      <td>8.864167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.71</td>\n",
       "      <td>75</td>\n",
       "      <td>40</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1008</td>\n",
       "      <td>29.80</td>\n",
       "      <td>8.75</td>\n",
       "      <td>8.764167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.01</td>\n",
       "      <td>75</td>\n",
       "      <td>39</td>\n",
       "      <td>14.6</td>\n",
       "      <td>1008</td>\n",
       "      <td>23.80</td>\n",
       "      <td>7.78</td>\n",
       "      <td>8.664167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.32</td>\n",
       "      <td>75</td>\n",
       "      <td>38</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1008</td>\n",
       "      <td>23.63</td>\n",
       "      <td>7.89</td>\n",
       "      <td>8.564167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.66</td>\n",
       "      <td>75</td>\n",
       "      <td>38</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1008</td>\n",
       "      <td>26.98</td>\n",
       "      <td>7.69</td>\n",
       "      <td>8.464167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   短期预测功率  短期预测湿度  短期预测风向  短期预测温度  短期预测气压   实际功率  实际风速    短期预测风速\n",
       "0   34.41      75      41    14.7    1008  28.59  8.50  8.864167\n",
       "1   33.71      75      40    14.7    1008  29.80  8.75  8.764167\n",
       "2   33.01      75      39    14.6    1008  23.80  7.78  8.664167\n",
       "3   32.32      75      38    14.5    1008  23.63  7.89  8.564167\n",
       "4   31.66      75      38    14.5    1008  26.98  7.69  8.464167"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43584, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetCopy = numpy.hstack([dataset[:,1:5],dataset[:,7:8]])\n",
    "datasetCopy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: keras==2.2.4 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (2.2.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (1.5.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (2.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from keras==2.2.4) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "43584/43584 [==============================] - 3s 62us/step - loss: 0.0180\n",
      "Epoch 2/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 2.9596e-04\n",
      "Epoch 3/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 1.6459e-04\n",
      "Epoch 4/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 1.1752e-04\n",
      "Epoch 5/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 9.1355e-05\n",
      "Epoch 6/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 7.3665e-05\n",
      "Epoch 7/20\n",
      "43584/43584 [==============================] - 1s 20us/step - loss: 5.8809e-05\n",
      "Epoch 8/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 4.8846e-05\n",
      "Epoch 9/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 4.1852e-05\n",
      "Epoch 10/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 3.6374e-05\n",
      "Epoch 11/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 3.1744e-05\n",
      "Epoch 12/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 2.8602e-05\n",
      "Epoch 13/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 2.6482e-05\n",
      "Epoch 14/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 2.2815e-05\n",
      "Epoch 15/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 2.1650e-05\n",
      "Epoch 16/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 1.9627e-05\n",
      "Epoch 17/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 1.8999e-05\n",
      "Epoch 18/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 1.7426e-05\n",
      "Epoch 19/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 1.7516e-05\n",
      "Epoch 20/20\n",
      "43584/43584 [==============================] - 1s 19us/step - loss: 1.5486e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f922d678278>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = Input(shape=(5,))\n",
    "encoded = Dense(128, activation='relu')(input)\n",
    "encoded1 = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(64, activation='relu')(encoded1)\n",
    "decoded1 = Dense(5, activation='tanh')(decoded)\n",
    "autoencoder = Model(input=input, output=decoded1)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.fit(datasetCopy, datasetCopy, epochs=20, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/ipykernel/__main__.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "encoderModel = Model(input=input, output=encoded1)\n",
    "encoded_input = Input(shape=(64,))  \n",
    "decoder_layer = autoencoder.layers[-1]  \n",
    "decoderModel = Model(inputs=encoded_input, outputs=decoder_layer(encoded_input))\n",
    "encoded_data = encoderModel.predict(datasetCopy)  \n",
    "datasetCopy = decoderModel.predict(encoded_data)\n",
    "#trainnewX = autoencoder.predict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43584, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetCopy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset,dataset1, look_back,look_lag,data_step):\n",
    "    main_dataX, main_dataY ,auxi_dataX,auxi_dataY= [], [],[],[]\n",
    "    for i in range(0,len(dataset)-look_back-look_lag+1,data_step):\n",
    "        a = dataset[i:(i+look_back), :] #5个\n",
    "        c = dataset[(i+look_back):(i+look_back+look_lag),:]#5个\n",
    "        d = dataset1[i:(i+look_back),5:7]#2个\n",
    "        e = numpy.hstack([a,c])\n",
    "        e = numpy.hstack([d,e])#把上面的特征都合在一起，共12个特征\n",
    "        main_dataX.append(e) #主要输入\n",
    "        b = dataset1[(i+look_back):(i+look_back+look_lag),5]\n",
    "        main_dataY.append(b) #主要输出 需要预测的功率数据\n",
    "    return numpy.array(main_dataX), numpy.array(main_dataY)#,numpy.array(auxi_dataX),numpy.array(auxi_dataY)\n",
    "\n",
    "\n",
    "look_back = 16\n",
    "look_lag = 16\n",
    "train_size = 364*96\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = datasetCopy[0:train_size,:], datasetCopy[train_size-look_back:len(dataset),:]\n",
    "train1, test1 = dataset[0:train_size,:], dataset[train_size-look_back:len(dataset),:]\n",
    "train_mainX, train_mainY = create_dataset(train, train1,look_back,look_lag,4)#,train_auxiX,train_auxiY\n",
    "test_mainX, test_mainY = create_dataset(test, test1,look_back,look_lag,16)#,test_auxiX,test_auxiY\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "train_mainX = numpy.reshape(train_mainX, (train_mainX.shape[0], look_back, 12))\n",
    "\n",
    "test_mainX = numpy.reshape(test_mainX, (test_mainX.shape[0], look_back, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 5848 samples, validate on 2881 samples\n",
      "Epoch 1/100\n",
      "5848/5848 [==============================] - 8s 1ms/step - loss: 0.0623 - val_loss: 0.0216\n",
      "Epoch 2/100\n",
      "5848/5848 [==============================] - 3s 459us/step - loss: 0.0271 - val_loss: 0.0174\n",
      "Epoch 3/100\n",
      "5848/5848 [==============================] - 3s 456us/step - loss: 0.0225 - val_loss: 0.0150\n",
      "Epoch 4/100\n",
      "5848/5848 [==============================] - 3s 456us/step - loss: 0.0202 - val_loss: 0.0141\n",
      "Epoch 5/100\n",
      "5848/5848 [==============================] - 3s 457us/step - loss: 0.0191 - val_loss: 0.0168\n",
      "Epoch 6/100\n",
      "5848/5848 [==============================] - 3s 456us/step - loss: 0.0175 - val_loss: 0.0128\n",
      "Epoch 7/100\n",
      "5848/5848 [==============================] - 3s 464us/step - loss: 0.0165 - val_loss: 0.0125\n",
      "Epoch 8/100\n",
      "5848/5848 [==============================] - 3s 457us/step - loss: 0.0163 - val_loss: 0.0135\n",
      "Epoch 9/100\n",
      "5848/5848 [==============================] - 3s 457us/step - loss: 0.0156 - val_loss: 0.0134\n",
      "Epoch 10/100\n",
      "5848/5848 [==============================] - 3s 457us/step - loss: 0.0152 - val_loss: 0.0125\n",
      "Epoch 11/100\n",
      "5848/5848 [==============================] - 3s 459us/step - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 12/100\n",
      "5848/5848 [==============================] - 3s 458us/step - loss: 0.0147 - val_loss: 0.0135\n",
      "Epoch 13/100\n",
      "5848/5848 [==============================] - 3s 454us/step - loss: 0.0146 - val_loss: 0.0135\n",
      "Epoch 14/100\n",
      "5848/5848 [==============================] - 3s 459us/step - loss: 0.0143 - val_loss: 0.0133\n",
      "Epoch 15/100\n",
      "5848/5848 [==============================] - 3s 457us/step - loss: 0.0140 - val_loss: 0.0116\n",
      "Epoch 16/100\n",
      "5848/5848 [==============================] - 3s 459us/step - loss: 0.0139 - val_loss: 0.0121\n",
      "Epoch 17/100\n",
      "5848/5848 [==============================] - 3s 459us/step - loss: 0.0138 - val_loss: 0.0116\n",
      "Epoch 18/100\n",
      "5848/5848 [==============================] - 3s 460us/step - loss: 0.0140 - val_loss: 0.0123\n",
      "Epoch 19/100\n",
      "5848/5848 [==============================] - 3s 460us/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 20/100\n",
      "5848/5848 [==============================] - 3s 450us/step - loss: 0.0135 - val_loss: 0.0113\n",
      "Epoch 21/100\n",
      "5848/5848 [==============================] - 3s 466us/step - loss: 0.0135 - val_loss: 0.0116\n",
      "Epoch 22/100\n",
      "5848/5848 [==============================] - 3s 454us/step - loss: 0.0135 - val_loss: 0.0135\n",
      "Epoch 23/100\n",
      "5848/5848 [==============================] - 3s 457us/step - loss: 0.0136 - val_loss: 0.0120\n",
      "Epoch 24/100\n",
      "5848/5848 [==============================] - 3s 457us/step - loss: 0.0132 - val_loss: 0.0111\n",
      "Epoch 25/100\n",
      "5848/5848 [==============================] - 3s 458us/step - loss: 0.0134 - val_loss: 0.0118\n",
      "Epoch 26/100\n",
      "5848/5848 [==============================] - 3s 456us/step - loss: 0.0134 - val_loss: 0.0112\n",
      "Epoch 27/100\n",
      "5848/5848 [==============================] - 3s 452us/step - loss: 0.0127 - val_loss: 0.0131\n",
      "Epoch 28/100\n",
      "5848/5848 [==============================] - 3s 458us/step - loss: 0.0131 - val_loss: 0.0111\n",
      "Epoch 29/100\n",
      "5848/5848 [==============================] - 3s 459us/step - loss: 0.0128 - val_loss: 0.0111\n",
      "Epoch 30/100\n",
      "5848/5848 [==============================] - 3s 451us/step - loss: 0.0127 - val_loss: 0.0111\n",
      "Epoch 31/100\n",
      "5848/5848 [==============================] - 3s 455us/step - loss: 0.0123 - val_loss: 0.0112\n",
      "Epoch 32/100\n",
      "5848/5848 [==============================] - 3s 459us/step - loss: 0.0127 - val_loss: 0.0110\n",
      "Epoch 33/100\n",
      "5848/5848 [==============================] - 3s 457us/step - loss: 0.0126 - val_loss: 0.0116\n",
      "Epoch 34/100\n",
      "5848/5848 [==============================] - 3s 465us/step - loss: 0.0127 - val_loss: 0.0115\n",
      "Epoch 35/100\n",
      "5848/5848 [==============================] - 3s 458us/step - loss: 0.0128 - val_loss: 0.0118\n",
      "Epoch 36/100\n",
      "5848/5848 [==============================] - 3s 458us/step - loss: 0.0126 - val_loss: 0.0110\n",
      "Epoch 37/100\n",
      "5848/5848 [==============================] - 3s 448us/step - loss: 0.0129 - val_loss: 0.0120\n",
      "Epoch 38/100\n",
      "5848/5848 [==============================] - 3s 449us/step - loss: 0.0123 - val_loss: 0.0110\n",
      "Epoch 39/100\n",
      "5848/5848 [==============================] - 3s 460us/step - loss: 0.0124 - val_loss: 0.0111\n",
      "Epoch 40/100\n",
      "5848/5848 [==============================] - 3s 462us/step - loss: 0.0122 - val_loss: 0.0116\n",
      "Epoch 41/100\n",
      "5848/5848 [==============================] - 3s 454us/step - loss: 0.0125 - val_loss: 0.0111\n",
      "Epoch 42/100\n",
      "5848/5848 [==============================] - 3s 460us/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 43/100\n",
      "5848/5848 [==============================] - 3s 458us/step - loss: 0.0125 - val_loss: 0.0113\n",
      "Epoch 44/100\n",
      "5848/5848 [==============================] - 3s 455us/step - loss: 0.0124 - val_loss: 0.0113\n",
      "Epoch 45/100\n",
      "5848/5848 [==============================] - 3s 455us/step - loss: 0.0123 - val_loss: 0.0121\n",
      "Epoch 46/100\n",
      "5848/5848 [==============================] - 3s 457us/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 47/100\n",
      "5848/5848 [==============================] - 3s 453us/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 48/100\n",
      "5848/5848 [==============================] - 3s 455us/step - loss: 0.0123 - val_loss: 0.0113\n",
      "Epoch 49/100\n",
      "5848/5848 [==============================] - 3s 456us/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 50/100\n",
      "5848/5848 [==============================] - 3s 453us/step - loss: 0.0122 - val_loss: 0.0110\n",
      "Epoch 51/100\n",
      "5848/5848 [==============================] - 3s 457us/step - loss: 0.0121 - val_loss: 0.0123\n",
      "Epoch 52/100\n",
      "5848/5848 [==============================] - 3s 455us/step - loss: 0.0121 - val_loss: 0.0111\n",
      "Epoch 53/100\n",
      "5848/5848 [==============================] - 3s 455us/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 54/100\n",
      "5848/5848 [==============================] - 3s 460us/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 55/100\n",
      "5848/5848 [==============================] - 3s 462us/step - loss: 0.0125 - val_loss: 0.0109\n",
      "Epoch 56/100\n",
      "5848/5848 [==============================] - 3s 456us/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 57/100\n",
      "5848/5848 [==============================] - 3s 458us/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 58/100\n",
      "5848/5848 [==============================] - 3s 461us/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 59/100\n",
      "5848/5848 [==============================] - 3s 517us/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 60/100\n",
      "5848/5848 [==============================] - 3s 456us/step - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 61/100\n",
      "5848/5848 [==============================] - 3s 455us/step - loss: 0.0123 - val_loss: 0.0114\n",
      "Epoch 62/100\n",
      "5848/5848 [==============================] - 3s 454us/step - loss: 0.0120 - val_loss: 0.0110\n",
      "Epoch 63/100\n",
      "5848/5848 [==============================] - 3s 451us/step - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 64/100\n",
      "5848/5848 [==============================] - 3s 455us/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 65/100\n",
      "5848/5848 [==============================] - 3s 458us/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 66/100\n",
      "5848/5848 [==============================] - 3s 458us/step - loss: 0.0120 - val_loss: 0.0109\n",
      "Epoch 67/100\n",
      "5848/5848 [==============================] - 3s 461us/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 68/100\n",
      "5848/5848 [==============================] - 3s 458us/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 69/100\n",
      "5848/5848 [==============================] - 3s 458us/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 70/100\n",
      "5848/5848 [==============================] - 3s 460us/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 71/100\n",
      "5848/5848 [==============================] - 3s 453us/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 72/100\n",
      "5848/5848 [==============================] - 3s 452us/step - loss: 0.0116 - val_loss: 0.0118\n",
      "Epoch 73/100\n",
      "5848/5848 [==============================] - 3s 456us/step - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 74/100\n",
      "5848/5848 [==============================] - 3s 460us/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 75/100\n",
      "5848/5848 [==============================] - 3s 461us/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 76/100\n",
      "5848/5848 [==============================] - 3s 458us/step - loss: 0.0117 - val_loss: 0.0120\n",
      "Epoch 77/100\n",
      "5848/5848 [==============================] - 3s 457us/step - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 78/100\n",
      "5848/5848 [==============================] - 3s 454us/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 79/100\n",
      "5848/5848 [==============================] - 3s 451us/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 80/100\n",
      "5848/5848 [==============================] - 3s 453us/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 81/100\n",
      "5848/5848 [==============================] - 3s 464us/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 82/100\n",
      "5848/5848 [==============================] - 3s 454us/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 83/100\n",
      "5848/5848 [==============================] - 3s 456us/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 84/100\n",
      "5848/5848 [==============================] - 3s 459us/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 85/100\n",
      "5848/5848 [==============================] - 3s 461us/step - loss: 0.0116 - val_loss: 0.0116\n",
      "Epoch 86/100\n",
      "5848/5848 [==============================] - 3s 458us/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 87/100\n",
      "5848/5848 [==============================] - 3s 455us/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 88/100\n",
      "5848/5848 [==============================] - 3s 481us/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 89/100\n",
      "5848/5848 [==============================] - 3s 459us/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 90/100\n",
      "5848/5848 [==============================] - 3s 451us/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 91/100\n",
      "5848/5848 [==============================] - 3s 452us/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 92/100\n",
      "5848/5848 [==============================] - 3s 455us/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 93/100\n",
      "5848/5848 [==============================] - 3s 452us/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 94/100\n",
      "5848/5848 [==============================] - 3s 447us/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 95/100\n",
      "5848/5848 [==============================] - 3s 454us/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 96/100\n",
      "5848/5848 [==============================] - 3s 452us/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 97/100\n",
      "5848/5848 [==============================] - 3s 459us/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 98/100\n",
      "5848/5848 [==============================] - 3s 450us/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 99/100\n",
      "5848/5848 [==============================] - 3s 456us/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 100/100\n",
      "5848/5848 [==============================] - 3s 454us/step - loss: 0.0111 - val_loss: 0.0111\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,Input,Masking\n",
    "from keras.layers import LSTM,Conv1D,MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation,concatenate\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from keras.engine import Layer\n",
    "import keras.backend as K\n",
    "from keras.layers import Multiply\n",
    "from keras.layers.core import *\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import *\n",
    "from keras.regularizers import l2\n",
    "#输入层\n",
    "main_input = Input(shape=(train_mainX.shape[1],train_mainX.shape[2]))\n",
    "#auxi_input = Input(shape=(train_auxiX.shape[1],train_auxiX.shape[2]))\n",
    "#模型1#\n",
    "#三层卷积层\n",
    "convolution1 = Conv1D(8, kernel_size=5, strides=1, activation='relu', padding='same')(main_input)\n",
    "Pool1 = MaxPooling1D(pool_size=3)(convolution1)\n",
    "convolution2 = Conv1D(8, kernel_size=5, strides=1, activation='relu', padding='same')(Pool1)\n",
    "Pool2 = MaxPooling1D(pool_size=3)(convolution2)\n",
    "#convolution3 = Conv1D(8, kernel_size=3, strides=1, activation='relu', padding='same')(convolution2)\n",
    "Flat = Flatten()(Pool2)\n",
    "Drop2 = Dropout(0.5)(Flat)\n",
    "\n",
    "#模型2\n",
    "#两层LSTM\n",
    "LSTM1 = LSTM(units=96, return_sequences=True)(main_input) \n",
    "#Drop3 = Dropout(0.2)(LSTM1)\n",
    "LSTM2 = LSTM(units=48, return_sequences=False)(LSTM1)\n",
    "Drop1 = Dropout(0.5)(LSTM2)\n",
    "#LSTM3 = LSTM(units=48, return_sequences=False)(LSTM2)\n",
    "#attention_mul = attention_3d_block(LSTM2)\n",
    "\n",
    "#模型1和模型2连接起来\n",
    "con = concatenate([Drop2,Drop1])\n",
    "#Flat = Flatten()(con)\n",
    "main_output = Dense(units = look_lag)(con)#主要输出\n",
    "#main_output = Dropout(0.2)(main_output)\n",
    "\n",
    "model = Model(inputs=main_input, outputs=main_output)\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "history = model.fit(train_mainX,train_mainY, validation_split=0.33,epochs=100, batch_size=120, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f91fc6effd0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.figure(figsize=(10,5))\n",
    "pyplot.plot(history.history['loss'], label='loss')\n",
    "pyplot.plot(history.history['val_loss'], label='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict = model.predict(test_mainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30.899076],\n",
       "       [31.113298],\n",
       "       [30.354488],\n",
       "       ...,\n",
       "       [34.850147],\n",
       "       [34.602688],\n",
       "       [34.117344]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPredict = testPredict.reshape(-1,1)\n",
    "testPredict = scaler_y.inverse_transform(testPredict)\n",
    "testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8640, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8640, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mainY = test_mainY.reshape(-1,1)\n",
    "test_mainY = scaler_y.inverse_transform(test_mainY)\n",
    "test_mainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "def result(testY,testPredict):\n",
    "    mse = mean_squared_error(testY,testPredict)\n",
    "    mae = mean_absolute_error(testY,testPredict)\n",
    "    r_square = r2_score(testY,testPredict)\n",
    "    print(\"MSE:\",mse)\n",
    "    print(\"MAE:\",mae)\n",
    "    print(\"R_Square:\",r_square)\n",
    "    rmse = math.sqrt(mse)\n",
    "    print(\"RMSE:\",rmse)\n",
    "    capacity = 49.5\n",
    "    print(\"NRMSE:\",1 - rmse/capacity)\n",
    "    p_hme = 0\n",
    "    whole_power = 49.5\n",
    "    for l in range(testY.shape[0]):\n",
    "        if testY[l] <= whole_power * 0.03 and testPredict[l] <= whole_power * 0.03:\n",
    "            continue\n",
    "        p_hme = p_hme + abs(testY[l] / (testY[l] + testPredict[l]) - 0.5) * abs(testPredict[l] -testY[l]) / np.sum(np.abs(testPredict - testY))\n",
    "    p_hme =  1 - 2 * p_hme\n",
    "    print('E', p_hme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019年1-3月结果：\n",
      "MSE: 26.642225\n",
      "MAE: 3.6755517\n",
      "R_Square: 0.8536901293438809\n",
      "RMSE: 5.161610723941019\n",
      "NRMSE: 0.8957250358799794\n",
      "E [0.7075358]\n",
      "2019年1月结果：\n",
      "MSE: 28.903872\n",
      "MAE: 3.9492047\n",
      "R_Square: 0.8236074154432336\n",
      "RMSE: 5.376232094716046\n",
      "NRMSE: 0.8913892506117971\n",
      "E 0.7433407676139516\n",
      "2019年2月结果：\n",
      "MSE: 25.930815\n",
      "MAE: 3.5834775\n",
      "R_Square: 0.8611526844789331\n",
      "RMSE: 5.0922308218542085\n",
      "NRMSE: 0.8971266500635513\n",
      "E 0.7216415628211568\n",
      "2019年3月结果：\n",
      "MSE: 25.02315\n",
      "MAE: 3.4850628\n",
      "R_Square: 0.8656223225434045\n",
      "RMSE: 5.002314413384713\n",
      "NRMSE: 0.8989431431639452\n",
      "E 0.6538609573620011\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions_1 = testPredict[0:31*96,0]\n",
    "predictions_2 = testPredict[31*96:59*96,0]\n",
    "predictions_3 = testPredict[59*96:90*96,0]\n",
    "\n",
    "test_labels_1 = test_mainY[0:31*96,0]\n",
    "test_labels_2 = test_mainY[31*96:59*96,0]\n",
    "test_labels_3 = test_mainY[59*96:90*96,0]\n",
    "\n",
    "print(\"2019年1-3月结果：\")\n",
    "result(test_mainY,testPredict)\n",
    "print(\"2019年1月结果：\")\n",
    "result(test_labels_1,predictions_1)\n",
    "print(\"2019年2月结果：\")\n",
    "result(test_labels_2,predictions_2)\n",
    "print(\"2019年3月结果：\")\n",
    "result(test_labels_3,predictions_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始系统准确率:\n",
      "2019年1-3月结果：\n",
      "MSE: 38.90323077467954\n",
      "MAE: 4.73843288221362\n",
      "R_Square: 0.7863569507222773\n",
      "RMSE: 6.237245447685985\n",
      "NRMSE: 0.8739950414608892\n",
      "E [0.66917906]\n",
      "2019年1月结果：\n",
      "MSE: 38.48454371279563\n",
      "MAE: 4.870769504471107\n",
      "R_Square: 0.7651391491589099\n",
      "RMSE: 6.203591194847999\n",
      "NRMSE: 0.8746749253566061\n",
      "E 0.7053141024294813\n",
      "2019年2月结果：\n",
      "MSE: 43.47097008356602\n",
      "MAE: 5.008162211467779\n",
      "R_Square: 0.7672333948800686\n",
      "RMSE: 6.593251859558076\n",
      "NRMSE: 0.8668029927362004\n",
      "E 0.6714997321255596\n",
      "2019年3月结果：\n",
      "MSE: 35.19621781563373\n",
      "MAE: 4.3624697690168945\n",
      "R_Square: 0.8109915717941774\n",
      "RMSE: 5.932640037591504\n",
      "NRMSE: 0.8801486861092626\n",
      "E 0.6264273692486862\n"
     ]
    }
   ],
   "source": [
    "#原系统准确率\n",
    "testorin=dataframe.values[train_size:,0]\n",
    "testorin=testorin.reshape(8640,1)\n",
    "systempredictions_1 = testorin[0:31*96,0]\n",
    "systempredictions_2 = testorin[31*96:59*96,0]\n",
    "systempredictions_3 = testorin[59*96:90*96,0]\n",
    "#原始系统准确率\n",
    "print(\"原始系统准确率:\")\n",
    "print(\"2019年1-3月结果：\")\n",
    "result(test_mainY,testorin)\n",
    "print(\"2019年1月结果：\")\n",
    "result(test_labels_1,systempredictions_1)\n",
    "print(\"2019年2月结果：\")\n",
    "result(test_labels_2,systempredictions_2)\n",
    "print(\"2019年3月结果：\")\n",
    "result(test_labels_3,systempredictions_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = numpy.hstack([test_mainY,testorin,testPredict])\n",
    "import pandas as pd\n",
    "new_data = pd.DataFrame(new_data,columns= ['实际功率','原系统预测功率','超短期预测功率'])\n",
    "new_data.to_csv('AE_lstm-ushort-89.78.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_py3",
   "language": "python",
   "name": "conda_tensorflow_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
