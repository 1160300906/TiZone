{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>labels</th>\n",
       "      <th>cmeclose</th>\n",
       "      <th>cmcclose</th>\n",
       "      <th>google</th>\n",
       "      <th>ravenpack</th>\n",
       "      <th>XAUprice</th>\n",
       "      <th>cmcvolume</th>\n",
       "      <th>market</th>\n",
       "      <th>AveBlockSize</th>\n",
       "      <th>...</th>\n",
       "      <th>CostPerTran</th>\n",
       "      <th>FeePerTran</th>\n",
       "      <th>MinRevenue</th>\n",
       "      <th>NetDifficulty</th>\n",
       "      <th>TolHashRate</th>\n",
       "      <th>TolTranFee</th>\n",
       "      <th>ConTranPerDay</th>\n",
       "      <th>EstTranValue</th>\n",
       "      <th>OutValue</th>\n",
       "      <th>UniAddressUsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-19</td>\n",
       "      <td>-1</td>\n",
       "      <td>17545</td>\n",
       "      <td>17776.7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.24737</td>\n",
       "      <td>1261.72</td>\n",
       "      <td>16894499840</td>\n",
       "      <td>3.162220e+11</td>\n",
       "      <td>1.060159</td>\n",
       "      <td>...</td>\n",
       "      <td>116.815051</td>\n",
       "      <td>32.003749</td>\n",
       "      <td>44228748.17</td>\n",
       "      <td>1873110000000</td>\n",
       "      <td>13035760.95</td>\n",
       "      <td>12117323.34</td>\n",
       "      <td>378622</td>\n",
       "      <td>3.906879e+09</td>\n",
       "      <td>1984897.730</td>\n",
       "      <td>887698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-20</td>\n",
       "      <td>-1</td>\n",
       "      <td>16490</td>\n",
       "      <td>16624.6</td>\n",
       "      <td>69</td>\n",
       "      <td>0.23034</td>\n",
       "      <td>1265.62</td>\n",
       "      <td>22149699584</td>\n",
       "      <td>2.775528e+11</td>\n",
       "      <td>1.072800</td>\n",
       "      <td>...</td>\n",
       "      <td>119.379078</td>\n",
       "      <td>41.644261</td>\n",
       "      <td>44203326.97</td>\n",
       "      <td>1873110000000</td>\n",
       "      <td>12663310.64</td>\n",
       "      <td>15419911.88</td>\n",
       "      <td>370277</td>\n",
       "      <td>5.449321e+09</td>\n",
       "      <td>2227875.178</td>\n",
       "      <td>853864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>-1</td>\n",
       "      <td>15555</td>\n",
       "      <td>15802.9</td>\n",
       "      <td>54</td>\n",
       "      <td>0.17781</td>\n",
       "      <td>1266.76</td>\n",
       "      <td>16516599808</td>\n",
       "      <td>2.781525e+11</td>\n",
       "      <td>1.038692</td>\n",
       "      <td>...</td>\n",
       "      <td>135.173009</td>\n",
       "      <td>54.790393</td>\n",
       "      <td>46165232.30</td>\n",
       "      <td>1873110000000</td>\n",
       "      <td>12290860.32</td>\n",
       "      <td>18712398.65</td>\n",
       "      <td>335482</td>\n",
       "      <td>3.765982e+09</td>\n",
       "      <td>1791086.429</td>\n",
       "      <td>840740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>-1</td>\n",
       "      <td>15555</td>\n",
       "      <td>13831.8</td>\n",
       "      <td>100</td>\n",
       "      <td>0.13745</td>\n",
       "      <td>1275.01</td>\n",
       "      <td>22197999616</td>\n",
       "      <td>2.602869e+11</td>\n",
       "      <td>1.062319</td>\n",
       "      <td>...</td>\n",
       "      <td>125.710492</td>\n",
       "      <td>54.637979</td>\n",
       "      <td>48973790.42</td>\n",
       "      <td>1873110000000</td>\n",
       "      <td>14432449.62</td>\n",
       "      <td>21285645.39</td>\n",
       "      <td>380648</td>\n",
       "      <td>4.135072e+09</td>\n",
       "      <td>1901698.950</td>\n",
       "      <td>890732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-23</td>\n",
       "      <td>1</td>\n",
       "      <td>15555</td>\n",
       "      <td>14699.2</td>\n",
       "      <td>63</td>\n",
       "      <td>0.08594</td>\n",
       "      <td>1275.01</td>\n",
       "      <td>13086000128</td>\n",
       "      <td>2.332497e+11</td>\n",
       "      <td>1.060038</td>\n",
       "      <td>...</td>\n",
       "      <td>135.118563</td>\n",
       "      <td>51.402623</td>\n",
       "      <td>41645027.49</td>\n",
       "      <td>1873110000000</td>\n",
       "      <td>12942648.37</td>\n",
       "      <td>15842853.90</td>\n",
       "      <td>308211</td>\n",
       "      <td>2.381108e+09</td>\n",
       "      <td>1781229.264</td>\n",
       "      <td>729638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  labels  cmeclose  cmcclose  google  ravenpack  XAUprice  \\\n",
       "0  2017-12-19      -1     17545   17776.7      52    0.24737   1261.72   \n",
       "1  2017-12-20      -1     16490   16624.6      69    0.23034   1265.62   \n",
       "2  2017-12-21      -1     15555   15802.9      54    0.17781   1266.76   \n",
       "3  2017-12-22      -1     15555   13831.8     100    0.13745   1275.01   \n",
       "4  2017-12-23       1     15555   14699.2      63    0.08594   1275.01   \n",
       "\n",
       "     cmcvolume        market  AveBlockSize  ...  CostPerTran  FeePerTran  \\\n",
       "0  16894499840  3.162220e+11      1.060159  ...   116.815051   32.003749   \n",
       "1  22149699584  2.775528e+11      1.072800  ...   119.379078   41.644261   \n",
       "2  16516599808  2.781525e+11      1.038692  ...   135.173009   54.790393   \n",
       "3  22197999616  2.602869e+11      1.062319  ...   125.710492   54.637979   \n",
       "4  13086000128  2.332497e+11      1.060038  ...   135.118563   51.402623   \n",
       "\n",
       "    MinRevenue  NetDifficulty  TolHashRate   TolTranFee  ConTranPerDay  \\\n",
       "0  44228748.17  1873110000000  13035760.95  12117323.34         378622   \n",
       "1  44203326.97  1873110000000  12663310.64  15419911.88         370277   \n",
       "2  46165232.30  1873110000000  12290860.32  18712398.65         335482   \n",
       "3  48973790.42  1873110000000  14432449.62  21285645.39         380648   \n",
       "4  41645027.49  1873110000000  12942648.37  15842853.90         308211   \n",
       "\n",
       "   EstTranValue     OutValue  UniAddressUsed  \n",
       "0  3.906879e+09  1984897.730          887698  \n",
       "1  5.449321e+09  2227875.178          853864  \n",
       "2  3.765982e+09  1791086.429          840740  \n",
       "3  4.135072e+09  1901698.950          890732  \n",
       "4  2.381108e+09  1781229.264          729638  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "dataframe1 = read_csv('DailyData1.csv', engine='python')\n",
    "dataframe = dataframe1.iloc[:,2:]\n",
    "dataset = dataframe.values\n",
    "# 将整型变为float\n",
    "dataset = dataset.astype('float64')\n",
    "dataframe1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(834, 23)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataframe1.iloc[:,1:2].values\n",
    "scaler1 = OneHotEncoder()\n",
    "labels = scaler1.fit_transform(labels)\n",
    "\n",
    "labels=labels.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(834, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset1,look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(0,len(dataset)-look_back,1):\n",
    "       # a1 = dataset[i:(i+look_back),:]\n",
    "        a2 = dataset1[i:(i+look_back),:]\n",
    "      #  a = numpy.hstack((a1,a2))\n",
    "        dataX.append(a2)\n",
    "        b = dataset1[(i+look_back):(i+look_back+1),1]\n",
    "        dataY.append(b)\n",
    "    return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(814,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 814 into shape (814,20,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8f411b687192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# reshape input to be [samples, time steps, features]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrainX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlook_back\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtestX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    299\u001b[0m            [5, 6]])\n\u001b[1;32m    300\u001b[0m     \"\"\"\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 814 into shape (814,20,2)"
     ]
    }
   ],
   "source": [
    "look_back = 20\n",
    "look_lag = 1 #用前20个数据预测当前1个数据\n",
    "train_size = 626\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[:train_size,:], dataset[train_size-look_back:len(dataset),:]\n",
    "train1, test1 = labels[:train_size,:], labels[train_size-look_back:len(dataset),:]\n",
    "trainX, trainY = create_dataset(train1,look_back)\n",
    "testX, testY = create_dataset(test1 ,look_back)\n",
    "print(trainX.shape)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], look_back,2))\n",
    "testX = numpy.reshape(testX, (testX.shape[0],look_back,2))\n",
    "\n",
    "features_set = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1]*2))\n",
    "scaler1 = StandardScaler().fit(features_set) #MinMaxScaler(feature_range=(-1, 1))\n",
    "features_set = scaler1.fit_transform(features_set)\n",
    "#pca=PCA(n_components=500).fit(features_set)\n",
    "#features_set = pca.transform(features_set)\n",
    "test_features = numpy.reshape(testX, (testX.shape[0], testX.shape[1]*2))\n",
    "test_features = scaler1.fit_transform(test_features)\n",
    "#test_features = pca.transform(test_features)\n",
    "\n",
    "def result(testY,testPredict):\n",
    "    from sklearn.metrics import accuracy_score,classification_report\n",
    "    acc = accuracy_score(testY,testPredict)\n",
    "    report = classification_report(testY,testPredict)\n",
    "    print(\"acc:\",acc)\n",
    "    print(report)\n",
    "\n",
    "trainY = trainY.reshape(trainY.shape[0])\n",
    "testY = testY.reshape(testY.shape[0])\n",
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "model1 = LR() #C=100,max_iter=5000\n",
    "model1.fit(features_set, trainY)\n",
    "testPredict1 = model1.predict(test_features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.5432692307692307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.52      0.56       115\n",
      "         1.0       0.49      0.57      0.53        93\n",
      "\n",
      "    accuracy                           0.54       208\n",
      "   macro avg       0.55      0.55      0.54       208\n",
      "weighted avg       0.55      0.54      0.54       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result(testY,testPredict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.5192307692307693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.52      0.55       115\n",
      "         1.0       0.47      0.52      0.49        93\n",
      "\n",
      "    accuracy                           0.52       208\n",
      "   macro avg       0.52      0.52      0.52       208\n",
      "weighted avg       0.52      0.52      0.52       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "model2 = LinearDiscriminantAnalysis() \n",
    "model2.fit(features_set, trainY)\n",
    "testPredict2 = model2.predict(test_features)  \n",
    "result(testY,testPredict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.5528846153846154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.57      0.58       115\n",
      "         1.0       0.50      0.54      0.52        93\n",
      "\n",
      "    accuracy                           0.55       208\n",
      "   macro avg       0.55      0.55      0.55       208\n",
      "weighted avg       0.56      0.55      0.55       208\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "model3 = QuadraticDiscriminantAnalysis() \n",
    "model3.fit(features_set, trainY)\n",
    "testPredict3 = model3.predict(test_features)  \n",
    "result(testY,testPredict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: xgboost in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from xgboost) (1.18.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from xgboost) (1.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.5528846153846154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.55      0.58       115\n",
      "         1.0       0.50      0.56      0.53        93\n",
      "\n",
      "    accuracy                           0.55       208\n",
      "   macro avg       0.55      0.55      0.55       208\n",
      "weighted avg       0.56      0.55      0.55       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "model4 = xgb.XGBClassifier(objective ='reg:logistic', colsample_bytree = 0.5, learning_rate = 0.003,\n",
    "                max_depth = 20, alpha = 20, n_estimators = 400)\n",
    "'''\n",
    "objective ='reg:logistic', colsample_bytree = 0.5, learning_rate = 0.003,\n",
    "                max_depth = 20, alpha = 20, n_estimators = 400\n",
    "'''\n",
    "model4.fit(features_set, trainY)\n",
    "testPredict4 = model4.predict(test_features)  \n",
    "result(testY,testPredict4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.5480769230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.50      0.55       115\n",
      "         1.0       0.50      0.60      0.54        93\n",
      "\n",
      "    accuracy                           0.55       208\n",
      "   macro avg       0.55      0.55      0.55       208\n",
      "weighted avg       0.56      0.55      0.55       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "model5 = svm.SVC()\n",
    "model5.fit(features_set, trainY)\n",
    "testPredict5 = model5.predict(test_features)  \n",
    "result(testY,testPredict5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "regr = RandomForestClassifier()#n_estimators=400,criterion=\"entropy\"\n",
    "regr.fit(features_set, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.5288461538461539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.47      0.52       115\n",
      "         1.0       0.48      0.60      0.53        93\n",
      "\n",
      "    accuracy                           0.53       208\n",
      "   macro avg       0.54      0.54      0.53       208\n",
      "weighted avg       0.54      0.53      0.53       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testPredict6 = regr.predict(test_features)  \n",
    "result(testY,testPredict6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting keras==2.2.4\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
      "\u001b[K     |████████████████████████████████| 312 kB 750 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 37.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /opt/conda/envs/python3/lib/python3.6/site-packages (from keras==2.2.4) (1.15.0)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 43.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/python3/lib/python3.6/site-packages (from keras==2.2.4) (1.18.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python3/lib/python3.6/site-packages (from keras==2.2.4) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/envs/python3/lib/python3.6/site-packages (from keras==2.2.4) (1.5.0)\n",
      "Collecting h5py\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: keras-preprocessing, h5py, keras-applications, keras\n",
      "Successfully installed h5py-2.10.0 keras-2.2.4 keras-applications-1.0.8 keras-preprocessing-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5376850f2dc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.6/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.6/site-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Globally-importable utils.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.6/site-packages/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.6/site-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Try and load external backend.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import keras\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,Conv1D,Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "%matplotlib inline\n",
    "from keras import optimizers,initializers\n",
    "model = Sequential() \n",
    "\n",
    "model.add(LSTM(units=96, return_sequences=True, \n",
    "               input_shape=(trainX.shape[1],trainX.shape[2])))#\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(LSTM(units=48, return_sequences=True,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(units=48,return_sequences=False,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "'''\n",
    "model.add(Conv1D(kernel_size=20, filters=3,activation='relu'))\n",
    "model.add(Flatten())\n",
    "'''\n",
    "\n",
    "#model.add(Dense(units = 16,activation='relu'))\n",
    "model.add(Dense(units = 1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',#binary_crossentropy\n",
    "                  optimizer='adam',#RMSprop optimizers.Adam(lr=0.00001)\n",
    "                  metrics=['accuracy'])  #mean_squared_error metrics=['accuracy']\n",
    "history = model.fit(trainX,trainY,epochs=500, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.5144230769230769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.42      0.49       115\n",
      "         1.0       0.47      0.63      0.54        93\n",
      "\n",
      "    accuracy                           0.51       208\n",
      "   macro avg       0.53      0.53      0.51       208\n",
      "weighted avg       0.53      0.51      0.51       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testPredict = model.predict_classes(testX)\n",
    "result(testY,testPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_py3",
   "language": "python",
   "name": "conda_tensorflow_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
